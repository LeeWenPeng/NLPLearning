# Context-Aware Neural Model for Temporal Information Extraction

时间：2018

作者：meng

方法：LSTM + 注意力机制

我们提出了一种用于时间信息提取的上下文感知神经网络模型，该模型具有事件-事件、事件-时间和时间-时间对的统一架构。受神经图灵机(NTM)启发，全局上下文层(GCL)以叙述顺序存储处理过的时间关系，并在遇到相关实体时检索它们以供使用。然后在这个更大的背景下对关系进行分类。**GCL模型使用长期记忆和注意机制来解决常规RNNs无法识别的长距离依赖关系**。**GCL不使用后处理来解决时间图冲突**，比以前的方法做得更好。据我们所知，GCL也是第一个使用类似ntm的架构将全球语境信息整合到自然文本的语篇尺度处理中的模型。

数据库：TimeBank-Dense(train)