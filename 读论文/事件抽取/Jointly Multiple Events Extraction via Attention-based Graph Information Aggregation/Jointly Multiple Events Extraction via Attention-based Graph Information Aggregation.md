摘要：

事件抽取在自然语言处理中具有实用价值。在现实世界中，在同一个句子中存在多个事件是一种常见的现象，提取这些事件比提取单个事件要困难得多。以前通过顺序建模方法对事件之间的关联进行建模的工作，由于在捕获非常长的依赖关系时效率很低，因此受到了很大的影响。本文提出了一种新的联合多事件提取(JMEE)框架，通过引入句法快捷弧来增强信息流和基于注意力的图卷积网络来对图信息建模，从而联合提取多事件触发器和论元。实验结果表明，我们提出的框架取得了与最先进的方法相比具有竞争力的结果。

**论文针对问题**：

​		同一句子存在多个事件的事件提取任务

**以往方法**：

+ 通过**顺序建模方法**对事件之间的**关联**进行建模
+ **缺陷**：在捕获非常长的依赖关系时效率很低

**提出**：联合多事件提取方法(Jointly Multiple Events Extraction, JMEE)

​		



这篇文章的目的是提出一种新的事件抽取框架，名为Jointly Multiple Events Extraction (JMEE) framework，用于自然语言处理中的事件抽取。该框架引入了**句法快捷弧**来增强信息流，并使用**基于注意力的图卷积网络来**建模图形信息。文章提出的自我注意机制可以在保持多个事件之间的关联的同时聚合信息。该框架在ACE 2005数据集上实现了最先进的性能。此外，文章还提出了一种**联合多任务学习框架**，用于事件抽取，**结合了图卷积网络和自我注意机制**，以捕捉事件之间的局部和全局依赖关系。该框架还使用了一个**有偏差的损失函数**来处理不平衡的数据，并联合提取事件触发器和参数。该方法在ACE 2005数据集上实现了最先进的性能。此外，文章还列出了一些与神经网络和其他技术相关的事件抽取研究论文的参考文献，涵盖了语言建模、跨实体推理和图卷积网络等主题。



该文章提出的联合多任务学习框架包括以下步骤：

1. 输入层：将原始文本输入模型，包括句子和实体信息。 
2. 词嵌入层：将输入的文本转换为词向量表示。 
3. 事件触发器分类层：**使用图卷积网络和自我注意机制来提取事件触发器，并使用有偏差的损失函数来处理不平衡的数据。** 
4. 参数角色标注层：使用相同的图卷积网络和自我注意机制来提取事件参数，并使用相同的有偏差的损失函数来处理不平衡的数据。 
5.  联合训练层：将事件触发器分类层和参数角色标注层联合起来进行训练，以捕捉事件之间的局部和全局依赖关系。
6. 输出层：输出事件触发器和参数角色标注的结果。 在训练过程中，该框架使用了联合损失函数，以最小化事件触发器分类和参数角色标注的误差。
7. 此外，该框架还使用了自我注意机制来聚合信息，以捕捉事件之间的关联。
8. 最终，该框架在ACE 2005数据集上实现了最先进的性能。



JMEE框架是一种新的事件抽取框架，它结合了句法快捷弧和基于注意力的图卷积网络，以建模图形信息和增强信息流。该框架采用联合多任务学习框架，用于事件触发器和事件参数的提取，并通过优化偏置损失函数来解决数据集中的不平衡问题。 具体来说，JMEE框架包括以下几个步骤： 

1. 句法快捷弧：在句法树中，JMEE框架引入了一些快捷弧，以增强信息流。这些快捷弧可以连接不同的节点，使得信息可以更快地传递。 
2. 图卷积网络：JMEE框架采用图卷积网络来建模图形信息。图卷积网络可以学习每个节点的上下文表示，通过节点的邻居节点来表示节点的语境信息。 
3. 自注意力机制：JMEE框架采用自注意力机制来聚合信息，特别是保持多个事件之间的关联。自注意力机制可以学习每个节点的重要性权重，以聚合节点的信息。
4. 联合多任务学习：JMEE框架采用联合多任务学习框架，同时提取事件触发器和事件参数。这种方法可以避免在管道中传播错误，并提高模型的准确性。
5. 优化偏置损失函数：JMEE框架通过优化偏置损失函数来解决数据集中的不平衡问题。该方法可以使模型更好地处理数据集中的少数类别。

 通过以上步骤，JMEE框架可以有效地提取。
