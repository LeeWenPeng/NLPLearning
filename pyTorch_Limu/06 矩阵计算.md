# 矩阵计算

将矩阵怎么求导

**作用**

对于机器学习和深度学习所有优化模型的求解都是通过求导进行的

## 1 标量求导

比如$x^n、e^x$等等之类的标量求导

**求导法则**

1.   链式法则
2.   莱布尼兹公式

## 2 亚导数

将导数扩展到不可导函数

比如$f(x) = |x|$对 $x$求导

则
$$
\frac {\partial f(x)} {\partial x} = 
\begin{cases}
1 &(x>0)\\
-1 &(x<0)\\
c &(x=0, c \in (-1, 1))
\end{cases}
$$
比如$f(x) = max(x,0)$对$x$求导
$$
\frac {\partial f(x)} {\partial x} = 
\begin{cases}
1 &(x>0)\\
0 &(x<0)\\
c &(x=0, c \in (0, 1))
\end{cases}
$$

## 梯度

将导数扩展到向量

|      | x         | y         | $\frac {\partial y} {\partial x}$ |
| ---- | --------- | --------- | --------------------------------- |
| 1    | 标量$x$   | 标量$y$   | 标量                              |
| 2    | 列向量$x$ | 标量$y$   | 行向量                            |
| 3    | 标量$x$   | 列向量$y$ | 列向量                            |
| 4    | 列向量$x$ | 向量$y$   | 矩阵                              |

## 情况2

>    梯度指向**值变化最大的方向**，也就是说，梯度通常与线段正交

先求出 $y$ 对每个 $x_i$ 的偏导数向量
$$
[{\frac {\partial y} {\partial {x_0}}}, {\frac {\partial y} {\partial {x_1}}},{\frac {\partial y} {\partial {x_2}}}, ... {\frac {\partial y} {\partial {x_n}}}]
$$

## 总结

所以如果是多个$x$和多个$y$，然后$y$对$x$求导的话，那就将每一个$y$对每一个$x$进行求导