# 文本预处理

## 0 准备工作

```python
# 导包
import collections
import re
from d2l import torch as d2l

# 下载数据集
d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a')
```



## 1 加载时光机器数据集

```python
def read_time_machine():
    """
    加载时间机器文本，并将文本安按行划分
    :return:
    """
    with open(d2l.download('time_machine'), 'r') as f:
        lines = f.readlines()
    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]

"""
1 加载数据集，获得行文本列表
"""
lines = read_time_machine()
print(lines[0])
print(lines[10])
```



## 2 将文本行列表转换成 tokens 列表

```python
def tokenize(lines, token='word'):
    "将文本行拆分为单词或字符标记"
    if token == 'word':
        return [line.split() for line in lines]
    elif token == 'char':
        return [list(line) for line in lines]
    else:
        print('错误，未知令牌指令' + token)

"""
2 将文本行列表转换成token列表
"""
tokens = tokenize(lines)
for i in range(11):
    print(tokens[i])
```



## 3 根据 tokens 列表生成词汇表

```python
class Vocab:
    """
    文本词汇表

    这里是一个标准的不可变容器，因为只定义了 __len__、__getitem__
    用双下划线包起来的函数叫做魔法函数
    """
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        """
        文本词汇表类的初始化函数
        这个函数会根据输入的tokens,创建词汇表
        其中会创建四个变量
        unk： 未知标记下标
        uniq_tokens：唯一词汇表
        idx_to_token：一个 list，可以通过 index 直接索引到 token
        token_to_idx：一个 dict，可以通过 token 直接索引到其对应的 index
        具体过程:
        1. 边界处理：如果 tokens 和 reserved_tokens 不存在就初始化为 []
        2. 统计 tokens 中的词频
        3. 根据词频将 tokens中的 token 排序
        4. 初始化位置 token unk = 0 并创建唯一词汇表 uniq_tokens
        5. 遍历 tokens 将当中所有唯一词加入到 uniq_tokens
        6. 创建一个 (list) idx_to_token 和一个 (dict) token_to_idx 来记录 index 和 token 之间关联
        7. 根据唯一词汇表 uniq_tokens 来更新 idx_to_token 和 token_to_idx
        :param tokens: 词标记
        :param min_freq: 最少出现频次，只有出现频次大于 min_freq 的 token 才会被加入到唯一词汇表中
        :param reserved_tokens:
        """
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        counter = count_corpus(tokens) # 统计词频
        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True) # 根据词频排序
        self.unk, uniq_tokens = 0, ['<unk'] + reserved_tokens
        uniq_tokens += [
            token for token, freq in self.token_freqs
            if freq >= min_freq and token not in uniq_tokens
        ]
        self.idx_to_token, self.token_to_idx = [], dict()
        for token in uniq_tokens:
            # self.idx_to_token.append(token)
            # self.token_to_idx[token] = len(self.idx_to_token) - 1
            self.token_to_idx[token] = len(self.idx_to_token)
            self.idx_to_token.append(token)



    def __len__(self):
        """返回容器长度的魔法方法"""
        return len(self.idx_to_token)
    def __getitem__(self, tokens):
        """
        __getitem__方法
        通过键获取值
        是一个魔法方法
        定义当某一项被访问，也就是vocab[tokens]时所做的行为
        :param tokens: token or [tokens]
        :return: indices
        """
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]

    def to_tokens(self, indices):
        """
        给 index 返回 index 对应的标记
        :param indices:
        :return: token or [tokens]
        """
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]

def count_corpus(tokens):
    """统计标记频率"""
    if len(tokens) == 0 or isinstance(tokens[0], list):
        tokens = [token for line in tokens for token in line]
    return collections.Counter(tokens)

"""
3 根据 token 构建词汇表 vocab
"""
vocab = Vocab(tokens)
print(list(vocab.token_to_idx.items())[:10])

"""
将每一行文本打印成一个数字索引列表
"""
for i in [0, 10]:
    print('words', tokens[i])
    print('indices', vocab[tokens[i]])
```



## 4 将上述功能打包

```python
def load_corpus_time_machine(max_tokens=-1):
    """
    将上述所有功能打包
    返回时光机器数据集的标记索引列表和词汇表
    """
    lines = read_time_machine()
    tokens = tokenize(lines, 'char')
    vocab = Vocab(tokens)
    corpus = [vocab[token] for line in tokens for token in line]
    if max_tokens > 0:
        corpus = corpus[:max_tokens]
    return corpus, vocab

corpus, vocab1 = load_corpus_time_machine()
print((len(corpus), len(vocab1)))
```



## 5 总代码

```python
import collections
import re
from d2l import torch as d2l

d2l.DATA_HUB['time_machine'] = (d2l.DATA_URL + 'timemachine.txt', '090b5e7e70c295757f55df93cb0a180b9691891a')

def read_time_machine():
    """加载时间机器文本，并将文本安按行划分"""
    with open(d2l.download('time_machine'), 'r') as f:
        lines = f.readlines()
    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines]

"""
1 加载数据集，获得行文本列表
"""
lines = read_time_machine()
# print(lines[0])
# print(lines[10])

def tokenize(lines, token='word'):
    "将文本行拆分为单词或字符标记"
    if token == 'word':
        return [line.split() for line in lines]
    elif token == 'char':
        return [list(line) for line in lines]
    else:
        print('错误，未知令牌指令' + token)

"""
2 将文本行列表转换成token列表
"""
tokens = tokenize(lines)
# for i in range(11):
#     print(tokens[i])

class Vocab:
    """文本词汇表"""
    def __init__(self, tokens=None, min_freq=0, reserved_tokens=None):
        if tokens is None:
            tokens = []
        if reserved_tokens is None:
            reserved_tokens = []
        counter = count_corpus(tokens) # 统计词频
        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True) # 根据词频排序
        self.unk, uniq_tokens = 0, ['<unk'] + reserved_tokens
        uniq_tokens += [
            token for token, freq in self.token_freqs
            if freq >= min_freq and token not in uniq_tokens
        ]
        self.idx_to_token, self.token_to_idx = [], dict()
        for token in uniq_tokens:
            # self.idx_to_token.append(token)
            # self.token_to_idx[token] = len(self.idx_to_token) - 1
            self.token_to_idx[token] = len(self.idx_to_token)
            self.idx_to_token.append(token)

    def __len__(self):
        """返回容器长度的魔法方法"""
        return len(self.idx_to_token)
    def __getitem__(self, tokens):
        if not isinstance(tokens, (list, tuple)):
            return self.token_to_idx.get(tokens, self.unk)
        return [self.__getitem__(token) for token in tokens]

    def to_tokens(self, indices):
        if not isinstance(indices, (list, tuple)):
            return self.idx_to_token[indices]
        return [self.idx_to_token[index] for index in indices]

def count_corpus(tokens):
    """统计标记频率"""
    if len(tokens) == 0 or isinstance(tokens[0], list):
        tokens = [token for line in tokens for token in line]
    return collections.Counter(tokens)

"""
3 根据 token 构建词汇表 vocab
"""
vocab = Vocab(tokens)
# print(list(vocab.token_to_idx.items())[:10])

"""
将每一行文本打印成一个数字索引列表
"""
# for i in [0, 10]:
#     print('words', tokens[i])
#     print('indices', vocab[tokens[i]])

def load_corpus_time_machine(max_tokens=-1):
    """将上述所有功能打包"""
    lines = read_time_machine()
    tokens = tokenize(lines, 'char')
    vocab = Vocab(tokens)
    corpus = [vocab[token] for line in tokens for token in line]
    if max_tokens > 0:
        corpus = corpus[:max_tokens]
    return corpus, vocab

corpus, vocab1 = load_corpus_time_machine()
print((len(corpus), len(vocab1)))
```

