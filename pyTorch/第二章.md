<<<<<<< HEAD
# 自然语言处理

文本处理工具——`spaCy`、`NLTK`



`n`元模型

`n`个词的序列



浅层解析：得到由语法元素组成的组合

浅层句法解析：识别短语词性

句法分析：识别短语之间的关系，形成句法分析树
=======
# 自然语言处理

文本处理工具`spaCy`和`NLTK`
> 使用工具`spaCy`

## 安装

1. 进入虚拟环境

   ```shell
    conda activate <虚拟环境>
   ```

2. spaCy 安装

    ```shell
    pip install spacy
    ```

3. 模型下载

   ```shell
    python -m spacy download <模型名>
    # 这里使用的是 en_core_web_sm
    python -m spacy download en_core_web_sm
   ```

## 初步使用

```python
import spacy

# 1 加载模型
nlp = spacy.load('en_core_web_sm')

text = "he was running late"

# 2 分词
doc = nlp(text)

cleaned = [str(token) for token in doc]
print(cleaned)

for token in doc:
    
    # 3 词形还原 token.lemma_
    print('{} --> {}'.format(token, token.lemma_))

    # 4 词性标注 token.pos_
    print('{} --> {}'.format(token, token.pos_))

# 5 名词短语分块
for chunk in doc.noun_chunks:
    print('{} --> {}'.format(chunk, chunk.label_))

# 6 n元模块
def n_grams(text, n):
    return [text[i:i+n] for i in range(len(text) - n + 1)]
# 3元模块
print(n_grams(cleaned, 3))
```
>>>>>>> ec7ba7a781d0aa6941e8d3cd848e1c903ca077ae
