# 第一章概述

介绍了几个概念

1. 监督学习范式
2. 样本和目标编码
   1. one-hot
   2. TF
   3. IDF-TF
   4. 目标编码
3. 计算图

## 1 监督学习范式

1. 监督学习范式的特点：
2. 监督学习范式的六个主要概念
   1. 样本：要预测的事物——$x$
   2. 目标：与样本对应的标签——$y$
   3. 模型：函数
   4. 参数：权重——$w$
   5. 预测：对样本猜测的目标值——$y^`$
   6. 损失函数：测量目标和预测值之间的误差——$L$\
3. 大概过程
   1. 对于数据集 $D = \{X_i,y_i\}_{i=1}^n$
   2. 对模型 $f$ 的结构做出假设
   3. 训练得到权重 $w$
   4. 对于给定的 $X$ ，得到预测值 $y^` =f(X,w)$
   5. 计算损失函数 $loss = L(y,y^`)$
4. 监督学习
   1. 主要任务：寻找 $n$ 个使 $loss$ 最小的权重 $w$
   2. 使用方法：梯度下降法， 随机梯度下降(SGD)

## 2 样本和目标编码

### 1 one-hot

1. 将每一个词汇作为分量，样本中所有词汇组成一个向量
2. 对于每一个样本，从0向量开始
3. 如果单词存在，则将对应分量设置为1，否则为0.

### 2 TF

1. 将每一个词汇作为分量，样本中所有词汇组成一个向量
2. 对于每一个样本，从0向量开始
3. 如果单词在该样本存在，则对应分量加一

> 一个短语、句子或文档的词频，就是其组成单词的one-hot表示向量的总和
>

使用**scikit-Learn库**生成的one-hot二进制表示

```python
for sk
```

### 3 TF-IDF

**IDF理念**：文档中词频与其对文档的作用呈反比
> 也就是说，这个方法基于的理念是，文档中出现越多的单词，反而 越没用，而罕见词相对质量更高
>

单词$w$的**IDF计算公式**
$$
IDF(w) = log{\frac{N}{n_w}}
$$

+ $n_w$ 表示存在单词$w$文档的数量
+ $N$ 所有文档总数

单词 $w$ 的**TF-IDF计算公式**
$$
TF-IDF(w) = TF(w) * IDF(w)
$$
